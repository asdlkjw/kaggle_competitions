{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec9f7749",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.layers import PReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import gc\n",
    "import pickle\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbe31191",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:9: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 28.5 s\n",
      "Wall time: 29.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "input_dir = '../inputs/favorita-grocery-sales-forecasting'\n",
    "\n",
    "df_train = pd.read_pickle('df_train_favorita.pkl')\n",
    "df_test = pd.read_pickle('df_test_favorita.pkl')\n",
    "items = pd.read_pickle('items_favorita.pkl')\n",
    "stores = pd.read_pickle('stores_favorita.pkl')\n",
    "\n",
    "\n",
    "df_2017 = df_train.loc[df_train.date>=pd.datetime(2017,1,1)]\n",
    "del df_train\n",
    "\n",
    "promo_2017_train = df_2017.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"onpromotion\"]].unstack(\n",
    "        level=-1).fillna(False)\n",
    "promo_2017_train.columns = promo_2017_train.columns.get_level_values(1)\n",
    "promo_2017_test = df_test[[\"onpromotion\"]].unstack(level=-1).fillna(False)\n",
    "promo_2017_test.columns = promo_2017_test.columns.get_level_values(1)\n",
    "promo_2017_test = promo_2017_test.reindex(promo_2017_train.index).fillna(False)\n",
    "promo_2017 = pd.concat([promo_2017_train, promo_2017_test], axis=1)\n",
    "del promo_2017_test, promo_2017_train\n",
    "\n",
    "df_2017 = df_2017.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"unit_sales\"]].unstack(\n",
    "        level=-1).fillna(0)\n",
    "df_2017.columns = df_2017.columns.get_level_values(1)\n",
    "\n",
    "items = items.reindex(df_2017.index.get_level_values(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf2342ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timespan(df, dt, minus, periods, freq='D'):\n",
    "    return df[pd.date_range(dt - timedelta(days=minus), periods=periods, freq=freq)]\n",
    "\n",
    "def prepare_dataset(t2017, is_train=True):\n",
    "    X = pd.DataFrame({\n",
    "        \"day_1_2017\": get_timespan(df_2017, t2017, 1, 1).values.ravel(),\n",
    "        \"mean_3_2017\": get_timespan(df_2017, t2017, 3, 3).mean(axis=1).values,\n",
    "        \"mean_7_2017\": get_timespan(df_2017, t2017, 7, 7).mean(axis=1).values,\n",
    "        \"mean_14_2017\": get_timespan(df_2017, t2017, 14, 14).mean(axis=1).values,\n",
    "        \"mean_30_2017\": get_timespan(df_2017, t2017, 30, 30).mean(axis=1).values,\n",
    "        \"mean_60_2017\": get_timespan(df_2017, t2017, 60, 60).mean(axis=1).values,\n",
    "        \"mean_140_2017\": get_timespan(df_2017, t2017, 140, 140).mean(axis=1).values,\n",
    "        \"promo_14_2017\": get_timespan(promo_2017, t2017, 14, 14).sum(axis=1).values,\n",
    "        \"promo_60_2017\": get_timespan(promo_2017, t2017, 60, 60).sum(axis=1).values,\n",
    "        \"promo_140_2017\": get_timespan(promo_2017, t2017, 140, 140).sum(axis=1).values\n",
    "    })\n",
    "    for i in range(7):\n",
    "        X['mean_4_dow{}_2017'.format(i)] = get_timespan(df_2017, t2017, 28-i, 4, freq='7D').mean(axis=1).values\n",
    "        X['mean_20_dow{}_2017'.format(i)] = get_timespan(df_2017, t2017, 140-i, 20, freq='7D').mean(axis=1).values\n",
    "    for i in range(16):\n",
    "        X[\"promo_{}\".format(i)] = promo_2017[f'{t2017 + timedelta(days=i)}'].values.astype(np.uint8)\n",
    "    if is_train:\n",
    "        y = df_2017[\n",
    "            pd.date_range(t2017, periods=16)\n",
    "        ].values\n",
    "        return X, y\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "764fb90c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset...\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing dataset...\")\n",
    "t2017 = date(2017, 5, 31)\n",
    "num_days= 8\n",
    "X_l, y_l = [], []\n",
    "for i in range(num_days):\n",
    "    delta = timedelta(days=7 * i)\n",
    "    X_tmp, y_tmp = prepare_dataset(t2017 + delta)\n",
    "    X_l.append(X_tmp)\n",
    "    y_l.append(y_tmp)\n",
    "X_train = pd.concat(X_l, axis=0)\n",
    "y_train = np.concatenate(y_l, axis=0)\n",
    "del X_l, y_l\n",
    "X_val, y_val = prepare_dataset(date(2017, 7, 26))\n",
    "X_test = prepare_dataset(date(2017, 8, 16), is_train=False)\n",
    "\n",
    "stores_items = pd.DataFrame(index=df_2017.index)\n",
    "test_ids = df_test[['id']]\n",
    "\n",
    "items = items.reindex( stores_items.index.get_level_values(1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "016bfa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 표준화를 사용 - 특성들을 정규분포로 만드는것이 정규화보다 좋다고 판단\n",
    "scaler = StandardScaler()  #MinMaxScaler() , RobustScaler()\n",
    "\n",
    "# 훈련데이터의 분포를 학습\n",
    "scaler.fit(pd.concat([X_train, X_val, X_test]))\n",
    "#데이터 적용\n",
    "X_train[:] = scaler.transform(X_train)\n",
    "X_val[:] = scaler.transform(X_val)\n",
    "X_test[:] = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ba404a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "X_val = X_val.values\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "X_val = X_val.reshape((X_val.shape[0], 1, X_val.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8de59c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(LSTM(32, input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "# model.add(Dropout(.1))\n",
    "# model.add(Dense(32))\n",
    "# model.add(Dropout(.2))\n",
    "# model.add(Dense(1))\n",
    "# model.compile(loss = 'mse', optimizer='adam', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5515f0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(256, input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.2))\n",
    "\n",
    "    model.add(Dense(128))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.1))\n",
    "\n",
    "    model.add(Dense(128))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.1))\n",
    "\n",
    "    model.add(Dense(64))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.05))\n",
    "\n",
    "    model.add(Dense(32))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.05))\n",
    "\n",
    "    model.add(Dense(16))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.05))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "852cd86f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Step 1\n",
      "==================================================\n",
      "Epoch 1/50\n",
      "1309/1309 - 23s - loss: 0.3556 - mse: 0.3368 - val_loss: 0.2959 - val_mse: 0.2959 - lr: 0.0100 - 23s/epoch - 17ms/step\n",
      "Epoch 2/50\n",
      "1309/1309 - 20s - loss: 0.3333 - mse: 0.3162 - val_loss: 0.3025 - val_mse: 0.3025 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 3/50\n",
      "1309/1309 - 20s - loss: 0.3316 - mse: 0.3146 - val_loss: 0.2961 - val_mse: 0.2961 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 4/50\n",
      "1309/1309 - 20s - loss: 0.3300 - mse: 0.3132 - val_loss: 0.3051 - val_mse: 0.3051 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 5/50\n",
      "1309/1309 - 20s - loss: 0.3296 - mse: 0.3128 - val_loss: 0.3002 - val_mse: 0.3002 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 6/50\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "1309/1309 - 20s - loss: 0.3291 - mse: 0.3124 - val_loss: 0.3065 - val_mse: 0.3065 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 7/50\n",
      "1309/1309 - 20s - loss: 0.3225 - mse: 0.3064 - val_loss: 0.2914 - val_mse: 0.2914 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 8/50\n",
      "1309/1309 - 20s - loss: 0.3210 - mse: 0.3050 - val_loss: 0.2906 - val_mse: 0.2906 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 9/50\n",
      "1309/1309 - 21s - loss: 0.3204 - mse: 0.3044 - val_loss: 0.2906 - val_mse: 0.2906 - lr: 1.0000e-03 - 21s/epoch - 16ms/step\n",
      "Epoch 10/50\n",
      "1309/1309 - 21s - loss: 0.3200 - mse: 0.3041 - val_loss: 0.2899 - val_mse: 0.2899 - lr: 1.0000e-03 - 21s/epoch - 16ms/step\n",
      "Epoch 11/50\n",
      "1309/1309 - 22s - loss: 0.3195 - mse: 0.3036 - val_loss: 0.2900 - val_mse: 0.2900 - lr: 1.0000e-03 - 22s/epoch - 17ms/step\n",
      "Epoch 12/50\n",
      "1309/1309 - 21s - loss: 0.3191 - mse: 0.3032 - val_loss: 0.2896 - val_mse: 0.2896 - lr: 1.0000e-03 - 21s/epoch - 16ms/step\n",
      "Epoch 13/50\n",
      "1309/1309 - 22s - loss: 0.3190 - mse: 0.3031 - val_loss: 0.2897 - val_mse: 0.2897 - lr: 1.0000e-03 - 22s/epoch - 17ms/step\n",
      "Epoch 14/50\n",
      "1309/1309 - 21s - loss: 0.3184 - mse: 0.3026 - val_loss: 0.2898 - val_mse: 0.2898 - lr: 1.0000e-03 - 21s/epoch - 16ms/step\n",
      "Epoch 15/50\n",
      "1309/1309 - 21s - loss: 0.3182 - mse: 0.3024 - val_loss: 0.2902 - val_mse: 0.2902 - lr: 1.0000e-03 - 21s/epoch - 16ms/step\n",
      "Epoch 16/50\n",
      "1309/1309 - 21s - loss: 0.3177 - mse: 0.3019 - val_loss: 0.2899 - val_mse: 0.2899 - lr: 1.0000e-03 - 21s/epoch - 16ms/step\n",
      "Epoch 17/50\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "1309/1309 - 21s - loss: 0.3180 - mse: 0.3022 - val_loss: 0.2896 - val_mse: 0.2896 - lr: 1.0000e-03 - 21s/epoch - 16ms/step\n",
      "Epoch 18/50\n",
      "1309/1309 - 22s - loss: 0.3167 - mse: 0.3010 - val_loss: 0.2894 - val_mse: 0.2894 - lr: 1.0000e-04 - 22s/epoch - 16ms/step\n",
      "Epoch 19/50\n",
      "1309/1309 - 21s - loss: 0.3164 - mse: 0.3008 - val_loss: 0.2894 - val_mse: 0.2894 - lr: 1.0000e-04 - 21s/epoch - 16ms/step\n",
      "Epoch 20/50\n",
      "1309/1309 - 21s - loss: 0.3164 - mse: 0.3007 - val_loss: 0.2895 - val_mse: 0.2895 - lr: 1.0000e-04 - 21s/epoch - 16ms/step\n",
      "Epoch 21/50\n",
      "1309/1309 - 21s - loss: 0.3162 - mse: 0.3005 - val_loss: 0.2894 - val_mse: 0.2894 - lr: 1.0000e-04 - 21s/epoch - 16ms/step\n",
      "Epoch 22/50\n",
      "1309/1309 - 22s - loss: 0.3160 - mse: 0.3004 - val_loss: 0.2895 - val_mse: 0.2895 - lr: 1.0000e-04 - 22s/epoch - 17ms/step\n",
      "Epoch 23/50\n",
      "1309/1309 - 22s - loss: 0.3162 - mse: 0.3006 - val_loss: 0.2895 - val_mse: 0.2895 - lr: 1.0000e-04 - 22s/epoch - 17ms/step\n",
      "Epoch 24/50\n",
      "1309/1309 - 21s - loss: 0.3160 - mse: 0.3004 - val_loss: 0.2895 - val_mse: 0.2895 - lr: 1.0000e-04 - 21s/epoch - 16ms/step\n",
      "Epoch 25/50\n",
      "1309/1309 - 21s - loss: 0.3157 - mse: 0.3001 - val_loss: 0.2895 - val_mse: 0.2895 - lr: 1.0000e-04 - 21s/epoch - 16ms/step\n",
      "Epoch 26/50\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "1309/1309 - 22s - loss: 0.3161 - mse: 0.3004 - val_loss: 0.2895 - val_mse: 0.2895 - lr: 1.0000e-04 - 22s/epoch - 17ms/step\n",
      "Epoch 27/50\n",
      "1309/1309 - 21s - loss: 0.3158 - mse: 0.3002 - val_loss: 0.2894 - val_mse: 0.2894 - lr: 1.0000e-05 - 21s/epoch - 16ms/step\n",
      "Epoch 28/50\n",
      "1309/1309 - 21s - loss: 0.3157 - mse: 0.3001 - val_loss: 0.2894 - val_mse: 0.2894 - lr: 1.0000e-05 - 21s/epoch - 16ms/step\n",
      "Epoch 29/50\n",
      "1309/1309 - 21s - loss: 0.3158 - mse: 0.3002 - val_loss: 0.2895 - val_mse: 0.2895 - lr: 1.0000e-05 - 21s/epoch - 16ms/step\n",
      "Epoch 30/50\n",
      "1309/1309 - 21s - loss: 0.3159 - mse: 0.3003 - val_loss: 0.2895 - val_mse: 0.2895 - lr: 1.0000e-05 - 21s/epoch - 16ms/step\n",
      "Epoch 31/50\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
      "1309/1309 - 21s - loss: 0.3159 - mse: 0.3003 - val_loss: 0.2894 - val_mse: 0.2894 - lr: 1.0000e-05 - 21s/epoch - 16ms/step\n",
      "==================================================\n",
      "Step 2\n",
      "==================================================\n",
      "Epoch 1/50\n",
      "1309/1309 - 22s - loss: 0.3715 - mse: 0.3504 - val_loss: 0.3487 - val_mse: 0.3487 - lr: 0.0100 - 22s/epoch - 17ms/step\n",
      "Epoch 2/50\n",
      "1309/1309 - 20s - loss: 0.3583 - mse: 0.3381 - val_loss: 0.3286 - val_mse: 0.3286 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 3/50\n",
      "1309/1309 - 20s - loss: 0.3568 - mse: 0.3367 - val_loss: 0.3372 - val_mse: 0.3372 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 4/50\n",
      "1309/1309 - 20s - loss: 0.3565 - mse: 0.3365 - val_loss: 0.3290 - val_mse: 0.3290 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 5/50\n",
      "1309/1309 - 20s - loss: 0.3557 - mse: 0.3357 - val_loss: 0.3260 - val_mse: 0.3260 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 6/50\n",
      "1309/1309 - 20s - loss: 0.3551 - mse: 0.3352 - val_loss: 0.3310 - val_mse: 0.3310 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 7/50\n",
      "1309/1309 - 20s - loss: 0.3539 - mse: 0.3341 - val_loss: 0.3243 - val_mse: 0.3243 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 8/50\n",
      "1309/1309 - 20s - loss: 0.3530 - mse: 0.3332 - val_loss: 0.3329 - val_mse: 0.3329 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 9/50\n",
      "1309/1309 - 20s - loss: 0.3526 - mse: 0.3328 - val_loss: 0.3271 - val_mse: 0.3271 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 10/50\n",
      "1309/1309 - 20s - loss: 0.3524 - mse: 0.3326 - val_loss: 0.3241 - val_mse: 0.3241 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 11/50\n",
      "1309/1309 - 20s - loss: 0.3519 - mse: 0.3322 - val_loss: 0.3243 - val_mse: 0.3243 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 12/50\n",
      "1309/1309 - 20s - loss: 0.3517 - mse: 0.3321 - val_loss: 0.3245 - val_mse: 0.3245 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 13/50\n",
      "1309/1309 - 20s - loss: 0.3509 - mse: 0.3313 - val_loss: 0.3229 - val_mse: 0.3229 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 14/50\n",
      "1309/1309 - 20s - loss: 0.3509 - mse: 0.3314 - val_loss: 0.3231 - val_mse: 0.3231 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 15/50\n",
      "1309/1309 - 20s - loss: 0.3508 - mse: 0.3312 - val_loss: 0.3269 - val_mse: 0.3269 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 16/50\n",
      "1309/1309 - 20s - loss: 0.3501 - mse: 0.3306 - val_loss: 0.3358 - val_mse: 0.3358 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 17/50\n",
      "1309/1309 - 20s - loss: 0.3502 - mse: 0.3306 - val_loss: 0.3230 - val_mse: 0.3230 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 18/50\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "1309/1309 - 20s - loss: 0.3497 - mse: 0.3302 - val_loss: 0.3269 - val_mse: 0.3269 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 19/50\n",
      "1309/1309 - 20s - loss: 0.3452 - mse: 0.3261 - val_loss: 0.3209 - val_mse: 0.3209 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 20/50\n",
      "1309/1309 - 20s - loss: 0.3441 - mse: 0.3250 - val_loss: 0.3212 - val_mse: 0.3212 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 21/50\n",
      "1309/1309 - 20s - loss: 0.3435 - mse: 0.3245 - val_loss: 0.3219 - val_mse: 0.3219 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 22/50\n",
      "1309/1309 - 20s - loss: 0.3433 - mse: 0.3243 - val_loss: 0.3205 - val_mse: 0.3205 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 23/50\n",
      "1309/1309 - 20s - loss: 0.3427 - mse: 0.3238 - val_loss: 0.3210 - val_mse: 0.3210 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 24/50\n",
      "1309/1309 - 20s - loss: 0.3425 - mse: 0.3236 - val_loss: 0.3208 - val_mse: 0.3208 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 25/50\n",
      "1309/1309 - 20s - loss: 0.3424 - mse: 0.3235 - val_loss: 0.3207 - val_mse: 0.3207 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 26/50\n",
      "1309/1309 - 20s - loss: 0.3422 - mse: 0.3234 - val_loss: 0.3210 - val_mse: 0.3210 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "1309/1309 - 20s - loss: 0.3417 - mse: 0.3229 - val_loss: 0.3217 - val_mse: 0.3217 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 28/50\n",
      "1309/1309 - 20s - loss: 0.3415 - mse: 0.3226 - val_loss: 0.3207 - val_mse: 0.3207 - lr: 1.0000e-04 - 20s/epoch - 15ms/step\n",
      "Epoch 29/50\n",
      "1309/1309 - 20s - loss: 0.3412 - mse: 0.3224 - val_loss: 0.3208 - val_mse: 0.3208 - lr: 1.0000e-04 - 20s/epoch - 15ms/step\n",
      "Epoch 30/50\n",
      "1309/1309 - 20s - loss: 0.3410 - mse: 0.3222 - val_loss: 0.3208 - val_mse: 0.3208 - lr: 1.0000e-04 - 20s/epoch - 15ms/step\n",
      "Epoch 31/50\n",
      "1309/1309 - 20s - loss: 0.3410 - mse: 0.3223 - val_loss: 0.3207 - val_mse: 0.3207 - lr: 1.0000e-04 - 20s/epoch - 15ms/step\n",
      "Epoch 32/50\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "1309/1309 - 20s - loss: 0.3409 - mse: 0.3221 - val_loss: 0.3208 - val_mse: 0.3208 - lr: 1.0000e-04 - 20s/epoch - 15ms/step\n",
      "==================================================\n",
      "Step 3\n",
      "==================================================\n",
      "Epoch 1/50\n",
      "1309/1309 - 22s - loss: 0.3791 - mse: 0.3589 - val_loss: 0.3452 - val_mse: 0.3452 - lr: 0.0100 - 22s/epoch - 17ms/step\n",
      "Epoch 2/50\n",
      "1309/1309 - 20s - loss: 0.3613 - mse: 0.3424 - val_loss: 0.3438 - val_mse: 0.3438 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 3/50\n",
      "1309/1309 - 20s - loss: 0.3597 - mse: 0.3409 - val_loss: 0.3494 - val_mse: 0.3494 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 4/50\n",
      "1309/1309 - 20s - loss: 0.3577 - mse: 0.3391 - val_loss: 0.3529 - val_mse: 0.3529 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 5/50\n",
      "1309/1309 - 20s - loss: 0.3574 - mse: 0.3388 - val_loss: 0.3433 - val_mse: 0.3433 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 6/50\n",
      "1309/1309 - 20s - loss: 0.3565 - mse: 0.3380 - val_loss: 0.3489 - val_mse: 0.3489 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 7/50\n",
      "1309/1309 - 20s - loss: 0.3559 - mse: 0.3374 - val_loss: 0.3501 - val_mse: 0.3501 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 8/50\n",
      "1309/1309 - 20s - loss: 0.3558 - mse: 0.3373 - val_loss: 0.3480 - val_mse: 0.3480 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 9/50\n",
      "1309/1309 - 20s - loss: 0.3548 - mse: 0.3364 - val_loss: 0.3418 - val_mse: 0.3418 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 10/50\n",
      "1309/1309 - 20s - loss: 0.3539 - mse: 0.3356 - val_loss: 0.3441 - val_mse: 0.3441 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 11/50\n",
      "1309/1309 - 20s - loss: 0.3540 - mse: 0.3357 - val_loss: 0.3435 - val_mse: 0.3435 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 12/50\n",
      "1309/1309 - 20s - loss: 0.3537 - mse: 0.3354 - val_loss: 0.3586 - val_mse: 0.3586 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 13/50\n",
      "1309/1309 - 20s - loss: 0.3528 - mse: 0.3346 - val_loss: 0.3368 - val_mse: 0.3368 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 14/50\n",
      "1309/1309 - 20s - loss: 0.3521 - mse: 0.3340 - val_loss: 0.3429 - val_mse: 0.3429 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 15/50\n",
      "1309/1309 - 20s - loss: 0.3521 - mse: 0.3339 - val_loss: 0.3450 - val_mse: 0.3450 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 16/50\n",
      "1309/1309 - 20s - loss: 0.3520 - mse: 0.3339 - val_loss: 0.3447 - val_mse: 0.3447 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 17/50\n",
      "1309/1309 - 20s - loss: 0.3516 - mse: 0.3335 - val_loss: 0.3409 - val_mse: 0.3409 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 18/50\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "1309/1309 - 20s - loss: 0.3511 - mse: 0.3331 - val_loss: 0.3394 - val_mse: 0.3394 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 19/50\n",
      "1309/1309 - 20s - loss: 0.3457 - mse: 0.3281 - val_loss: 0.3384 - val_mse: 0.3384 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 20/50\n",
      "1309/1309 - 20s - loss: 0.3447 - mse: 0.3271 - val_loss: 0.3375 - val_mse: 0.3375 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 21/50\n",
      "1309/1309 - 20s - loss: 0.3443 - mse: 0.3268 - val_loss: 0.3383 - val_mse: 0.3383 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 22/50\n",
      "1309/1309 - 20s - loss: 0.3438 - mse: 0.3264 - val_loss: 0.3380 - val_mse: 0.3380 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 23/50\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "1309/1309 - 20s - loss: 0.3431 - mse: 0.3257 - val_loss: 0.3388 - val_mse: 0.3388 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "==================================================\n",
      "Step 4\n",
      "==================================================\n",
      "Epoch 1/50\n",
      "1309/1309 - 22s - loss: 0.4057 - mse: 0.3836 - val_loss: 0.3624 - val_mse: 0.3624 - lr: 0.0100 - 22s/epoch - 17ms/step\n",
      "Epoch 2/50\n",
      "1309/1309 - 20s - loss: 0.3871 - mse: 0.3662 - val_loss: 0.3624 - val_mse: 0.3624 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 3/50\n",
      "1309/1309 - 20s - loss: 0.3843 - mse: 0.3637 - val_loss: 0.3737 - val_mse: 0.3737 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 4/50\n",
      "1309/1309 - 20s - loss: 0.3839 - mse: 0.3633 - val_loss: 0.3641 - val_mse: 0.3641 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 5/50\n",
      "1309/1309 - 20s - loss: 0.3826 - mse: 0.3620 - val_loss: 0.3525 - val_mse: 0.3525 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 6/50\n",
      "1309/1309 - 20s - loss: 0.3819 - mse: 0.3614 - val_loss: 0.3543 - val_mse: 0.3543 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 7/50\n",
      "1309/1309 - 20s - loss: 0.3813 - mse: 0.3609 - val_loss: 0.3530 - val_mse: 0.3530 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 8/50\n",
      "1309/1309 - 20s - loss: 0.3803 - mse: 0.3599 - val_loss: 0.3578 - val_mse: 0.3578 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 9/50\n",
      "1309/1309 - 20s - loss: 0.3799 - mse: 0.3596 - val_loss: 0.3528 - val_mse: 0.3528 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 10/50\n",
      "1309/1309 - 20s - loss: 0.3787 - mse: 0.3584 - val_loss: 0.3503 - val_mse: 0.3503 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 11/50\n",
      "1309/1309 - 20s - loss: 0.3783 - mse: 0.3580 - val_loss: 0.3555 - val_mse: 0.3555 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 12/50\n",
      "1309/1309 - 20s - loss: 0.3782 - mse: 0.3579 - val_loss: 0.3604 - val_mse: 0.3604 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 13/50\n",
      "1309/1309 - 20s - loss: 0.3781 - mse: 0.3578 - val_loss: 0.3510 - val_mse: 0.3510 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 14/50\n",
      "1309/1309 - 20s - loss: 0.3773 - mse: 0.3571 - val_loss: 0.3551 - val_mse: 0.3551 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 15/50\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "1309/1309 - 20s - loss: 0.3767 - mse: 0.3566 - val_loss: 0.3541 - val_mse: 0.3541 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 16/50\n",
      "1309/1309 - 20s - loss: 0.3716 - mse: 0.3518 - val_loss: 0.3476 - val_mse: 0.3476 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 17/50\n",
      "1309/1309 - 20s - loss: 0.3699 - mse: 0.3503 - val_loss: 0.3479 - val_mse: 0.3479 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 18/50\n",
      "1309/1309 - 20s - loss: 0.3689 - mse: 0.3494 - val_loss: 0.3478 - val_mse: 0.3478 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 19/50\n",
      "1309/1309 - 20s - loss: 0.3690 - mse: 0.3494 - val_loss: 0.3477 - val_mse: 0.3477 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 20/50\n",
      "1309/1309 - 20s - loss: 0.3684 - mse: 0.3489 - val_loss: 0.3478 - val_mse: 0.3478 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 21/50\n",
      "1309/1309 - 20s - loss: 0.3682 - mse: 0.3487 - val_loss: 0.3474 - val_mse: 0.3474 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 22/50\n",
      "1309/1309 - 20s - loss: 0.3679 - mse: 0.3485 - val_loss: 0.3482 - val_mse: 0.3482 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 23/50\n",
      "1309/1309 - 20s - loss: 0.3678 - mse: 0.3483 - val_loss: 0.3480 - val_mse: 0.3480 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 24/50\n",
      "1309/1309 - 20s - loss: 0.3670 - mse: 0.3476 - val_loss: 0.3481 - val_mse: 0.3481 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 25/50\n",
      "1309/1309 - 20s - loss: 0.3672 - mse: 0.3478 - val_loss: 0.3497 - val_mse: 0.3497 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 26/50\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "1309/1309 - 20s - loss: 0.3669 - mse: 0.3475 - val_loss: 0.3479 - val_mse: 0.3479 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 27/50\n",
      "1309/1309 - 20s - loss: 0.3660 - mse: 0.3467 - val_loss: 0.3478 - val_mse: 0.3478 - lr: 1.0000e-04 - 20s/epoch - 15ms/step\n",
      "Epoch 28/50\n",
      "1309/1309 - 20s - loss: 0.3659 - mse: 0.3466 - val_loss: 0.3478 - val_mse: 0.3478 - lr: 1.0000e-04 - 20s/epoch - 15ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "1309/1309 - 20s - loss: 0.3656 - mse: 0.3463 - val_loss: 0.3479 - val_mse: 0.3479 - lr: 1.0000e-04 - 20s/epoch - 15ms/step\n",
      "Epoch 30/50\n",
      "1309/1309 - 20s - loss: 0.3658 - mse: 0.3465 - val_loss: 0.3478 - val_mse: 0.3478 - lr: 1.0000e-04 - 20s/epoch - 15ms/step\n",
      "Epoch 31/50\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "1309/1309 - 20s - loss: 0.3655 - mse: 0.3463 - val_loss: 0.3479 - val_mse: 0.3479 - lr: 1.0000e-04 - 20s/epoch - 15ms/step\n",
      "==================================================\n",
      "Step 5\n",
      "==================================================\n",
      "Epoch 1/50\n",
      "1309/1309 - 22s - loss: 0.4164 - mse: 0.3938 - val_loss: 0.3732 - val_mse: 0.3732 - lr: 0.0100 - 22s/epoch - 17ms/step\n",
      "Epoch 2/50\n",
      "1309/1309 - 20s - loss: 0.3985 - mse: 0.3771 - val_loss: 0.3602 - val_mse: 0.3602 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 3/50\n",
      "1309/1309 - 20s - loss: 0.3960 - mse: 0.3748 - val_loss: 0.3777 - val_mse: 0.3777 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 4/50\n",
      "1309/1309 - 20s - loss: 0.3949 - mse: 0.3739 - val_loss: 0.3620 - val_mse: 0.3620 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 5/50\n",
      "1309/1309 - 20s - loss: 0.3937 - mse: 0.3727 - val_loss: 0.3666 - val_mse: 0.3666 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 6/50\n",
      "1309/1309 - 20s - loss: 0.3924 - mse: 0.3715 - val_loss: 0.3548 - val_mse: 0.3548 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 7/50\n",
      "1309/1309 - 20s - loss: 0.3913 - mse: 0.3706 - val_loss: 0.3726 - val_mse: 0.3726 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 8/50\n",
      "1309/1309 - 20s - loss: 0.3907 - mse: 0.3700 - val_loss: 0.3563 - val_mse: 0.3563 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 9/50\n",
      "1309/1309 - 20s - loss: 0.3899 - mse: 0.3692 - val_loss: 0.3575 - val_mse: 0.3575 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 10/50\n",
      "1309/1309 - 20s - loss: 0.3894 - mse: 0.3688 - val_loss: 0.3611 - val_mse: 0.3611 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 11/50\n",
      "1309/1309 - 20s - loss: 0.3891 - mse: 0.3685 - val_loss: 0.3545 - val_mse: 0.3545 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 12/50\n",
      "1309/1309 - 20s - loss: 0.3885 - mse: 0.3679 - val_loss: 0.3696 - val_mse: 0.3696 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 13/50\n",
      "1309/1309 - 20s - loss: 0.3876 - mse: 0.3671 - val_loss: 0.3610 - val_mse: 0.3610 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 14/50\n",
      "1309/1309 - 20s - loss: 0.3872 - mse: 0.3667 - val_loss: 0.3521 - val_mse: 0.3521 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 15/50\n",
      "1309/1309 - 20s - loss: 0.3867 - mse: 0.3662 - val_loss: 0.3600 - val_mse: 0.3600 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 16/50\n",
      "1309/1309 - 20s - loss: 0.3867 - mse: 0.3662 - val_loss: 0.3600 - val_mse: 0.3600 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 17/50\n",
      "1309/1309 - 20s - loss: 0.3865 - mse: 0.3661 - val_loss: 0.3592 - val_mse: 0.3592 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 18/50\n",
      "1309/1309 - 20s - loss: 0.3857 - mse: 0.3654 - val_loss: 0.3568 - val_mse: 0.3568 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 19/50\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "1309/1309 - 20s - loss: 0.3854 - mse: 0.3651 - val_loss: 0.3568 - val_mse: 0.3568 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 20/50\n",
      "1309/1309 - 20s - loss: 0.3800 - mse: 0.3601 - val_loss: 0.3519 - val_mse: 0.3519 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 21/50\n",
      "1309/1309 - 19s - loss: 0.3783 - mse: 0.3585 - val_loss: 0.3516 - val_mse: 0.3516 - lr: 1.0000e-03 - 19s/epoch - 15ms/step\n",
      "Epoch 22/50\n",
      "1309/1309 - 19s - loss: 0.3777 - mse: 0.3579 - val_loss: 0.3520 - val_mse: 0.3520 - lr: 1.0000e-03 - 19s/epoch - 15ms/step\n",
      "Epoch 23/50\n",
      "1309/1309 - 19s - loss: 0.3773 - mse: 0.3576 - val_loss: 0.3520 - val_mse: 0.3520 - lr: 1.0000e-03 - 19s/epoch - 15ms/step\n",
      "Epoch 24/50\n",
      "1309/1309 - 19s - loss: 0.3769 - mse: 0.3572 - val_loss: 0.3515 - val_mse: 0.3515 - lr: 1.0000e-03 - 19s/epoch - 15ms/step\n",
      "Epoch 25/50\n",
      "1309/1309 - 19s - loss: 0.3766 - mse: 0.3570 - val_loss: 0.3516 - val_mse: 0.3516 - lr: 1.0000e-03 - 19s/epoch - 15ms/step\n",
      "Epoch 26/50\n",
      "1309/1309 - 19s - loss: 0.3766 - mse: 0.3570 - val_loss: 0.3518 - val_mse: 0.3518 - lr: 1.0000e-03 - 19s/epoch - 15ms/step\n",
      "Epoch 27/50\n",
      "1309/1309 - 19s - loss: 0.3763 - mse: 0.3567 - val_loss: 0.3520 - val_mse: 0.3520 - lr: 1.0000e-03 - 19s/epoch - 15ms/step\n",
      "Epoch 28/50\n",
      "1309/1309 - 19s - loss: 0.3758 - mse: 0.3562 - val_loss: 0.3522 - val_mse: 0.3522 - lr: 1.0000e-03 - 19s/epoch - 15ms/step\n",
      "Epoch 29/50\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "1309/1309 - 19s - loss: 0.3756 - mse: 0.3560 - val_loss: 0.3520 - val_mse: 0.3520 - lr: 1.0000e-03 - 19s/epoch - 15ms/step\n",
      "Epoch 30/50\n",
      "1309/1309 - 19s - loss: 0.3750 - mse: 0.3554 - val_loss: 0.3518 - val_mse: 0.3518 - lr: 1.0000e-04 - 19s/epoch - 15ms/step\n",
      "Epoch 31/50\n",
      "1309/1309 - 19s - loss: 0.3748 - mse: 0.3553 - val_loss: 0.3518 - val_mse: 0.3518 - lr: 1.0000e-04 - 19s/epoch - 15ms/step\n",
      "Epoch 32/50\n",
      "1309/1309 - 19s - loss: 0.3748 - mse: 0.3553 - val_loss: 0.3518 - val_mse: 0.3518 - lr: 1.0000e-04 - 19s/epoch - 15ms/step\n",
      "Epoch 33/50\n",
      "1309/1309 - 19s - loss: 0.3746 - mse: 0.3551 - val_loss: 0.3518 - val_mse: 0.3518 - lr: 1.0000e-04 - 19s/epoch - 15ms/step\n",
      "Epoch 34/50\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "1309/1309 - 19s - loss: 0.3746 - mse: 0.3551 - val_loss: 0.3518 - val_mse: 0.3518 - lr: 1.0000e-04 - 19s/epoch - 15ms/step\n",
      "==================================================\n",
      "Step 6\n",
      "==================================================\n",
      "Epoch 1/50\n",
      "1309/1309 - 22s - loss: 0.4104 - mse: 0.3866 - val_loss: 0.3602 - val_mse: 0.3602 - lr: 0.0100 - 22s/epoch - 17ms/step\n",
      "Epoch 2/50\n",
      "1309/1309 - 20s - loss: 0.3916 - mse: 0.3693 - val_loss: 0.3566 - val_mse: 0.3566 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 3/50\n",
      "1309/1309 - 20s - loss: 0.3899 - mse: 0.3676 - val_loss: 0.3645 - val_mse: 0.3645 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 4/50\n",
      "1309/1309 - 20s - loss: 0.3892 - mse: 0.3671 - val_loss: 0.3629 - val_mse: 0.3629 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 5/50\n",
      "1309/1309 - 20s - loss: 0.3884 - mse: 0.3663 - val_loss: 0.3571 - val_mse: 0.3571 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 6/50\n",
      "1309/1309 - 20s - loss: 0.3875 - mse: 0.3655 - val_loss: 0.3596 - val_mse: 0.3596 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 7/50\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "1309/1309 - 19s - loss: 0.3871 - mse: 0.3651 - val_loss: 0.3598 - val_mse: 0.3598 - lr: 0.0100 - 19s/epoch - 15ms/step\n",
      "Epoch 8/50\n",
      "1309/1309 - 19s - loss: 0.3805 - mse: 0.3591 - val_loss: 0.3566 - val_mse: 0.3566 - lr: 1.0000e-03 - 19s/epoch - 15ms/step\n",
      "Epoch 9/50\n",
      "1309/1309 - 20s - loss: 0.3789 - mse: 0.3577 - val_loss: 0.3567 - val_mse: 0.3567 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 10/50\n",
      "1309/1309 - 20s - loss: 0.3782 - mse: 0.3570 - val_loss: 0.3589 - val_mse: 0.3589 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 11/50\n",
      "1309/1309 - 20s - loss: 0.3777 - mse: 0.3565 - val_loss: 0.3563 - val_mse: 0.3563 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 12/50\n",
      "1309/1309 - 20s - loss: 0.3771 - mse: 0.3559 - val_loss: 0.3570 - val_mse: 0.3570 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 13/50\n",
      "1309/1309 - 20s - loss: 0.3765 - mse: 0.3554 - val_loss: 0.3558 - val_mse: 0.3558 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 14/50\n",
      "1309/1309 - 20s - loss: 0.3759 - mse: 0.3549 - val_loss: 0.3555 - val_mse: 0.3555 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 15/50\n",
      "1309/1309 - 20s - loss: 0.3760 - mse: 0.3550 - val_loss: 0.3569 - val_mse: 0.3569 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 16/50\n",
      "1309/1309 - 20s - loss: 0.3757 - mse: 0.3547 - val_loss: 0.3555 - val_mse: 0.3555 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 17/50\n",
      "1309/1309 - 20s - loss: 0.3751 - mse: 0.3541 - val_loss: 0.3599 - val_mse: 0.3599 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 18/50\n",
      "1309/1309 - 20s - loss: 0.3749 - mse: 0.3539 - val_loss: 0.3565 - val_mse: 0.3565 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 19/50\n",
      "1309/1309 - 19s - loss: 0.3750 - mse: 0.3540 - val_loss: 0.3575 - val_mse: 0.3575 - lr: 1.0000e-03 - 19s/epoch - 15ms/step\n",
      "Epoch 20/50\n",
      "1309/1309 - 20s - loss: 0.3743 - mse: 0.3534 - val_loss: 0.3572 - val_mse: 0.3572 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "1309/1309 - 20s - loss: 0.3744 - mse: 0.3535 - val_loss: 0.3562 - val_mse: 0.3562 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 22/50\n",
      "1309/1309 - 20s - loss: 0.3731 - mse: 0.3523 - val_loss: 0.3567 - val_mse: 0.3567 - lr: 1.0000e-04 - 20s/epoch - 15ms/step\n",
      "Epoch 23/50\n",
      "1309/1309 - 20s - loss: 0.3728 - mse: 0.3520 - val_loss: 0.3569 - val_mse: 0.3569 - lr: 1.0000e-04 - 20s/epoch - 15ms/step\n",
      "Epoch 24/50\n",
      "1309/1309 - 20s - loss: 0.3728 - mse: 0.3520 - val_loss: 0.3568 - val_mse: 0.3568 - lr: 1.0000e-04 - 20s/epoch - 15ms/step\n",
      "Epoch 25/50\n",
      "1309/1309 - 20s - loss: 0.3724 - mse: 0.3517 - val_loss: 0.3568 - val_mse: 0.3568 - lr: 1.0000e-04 - 20s/epoch - 15ms/step\n",
      "Epoch 26/50\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "1309/1309 - 20s - loss: 0.3726 - mse: 0.3518 - val_loss: 0.3570 - val_mse: 0.3570 - lr: 1.0000e-04 - 20s/epoch - 15ms/step\n",
      "==================================================\n",
      "Step 7\n",
      "==================================================\n",
      "Epoch 1/50\n",
      "1309/1309 - 22s - loss: 0.3990 - mse: 0.3767 - val_loss: 0.4307 - val_mse: 0.4307 - lr: 0.0100 - 22s/epoch - 17ms/step\n",
      "Epoch 2/50\n",
      "1309/1309 - 21s - loss: 0.3801 - mse: 0.3593 - val_loss: 0.4272 - val_mse: 0.4272 - lr: 0.0100 - 21s/epoch - 16ms/step\n",
      "Epoch 3/50\n",
      "1309/1309 - 21s - loss: 0.3784 - mse: 0.3578 - val_loss: 0.4210 - val_mse: 0.4210 - lr: 0.0100 - 21s/epoch - 16ms/step\n",
      "Epoch 4/50\n",
      "1309/1309 - 20s - loss: 0.3776 - mse: 0.3571 - val_loss: 0.4371 - val_mse: 0.4371 - lr: 0.0100 - 20s/epoch - 16ms/step\n",
      "Epoch 5/50\n",
      "1309/1309 - 20s - loss: 0.3769 - mse: 0.3565 - val_loss: 0.4101 - val_mse: 0.4101 - lr: 0.0100 - 20s/epoch - 16ms/step\n",
      "Epoch 6/50\n",
      "1309/1309 - 20s - loss: 0.3755 - mse: 0.3551 - val_loss: 0.4160 - val_mse: 0.4160 - lr: 0.0100 - 20s/epoch - 16ms/step\n",
      "Epoch 7/50\n",
      "1309/1309 - 20s - loss: 0.3746 - mse: 0.3544 - val_loss: 0.4258 - val_mse: 0.4258 - lr: 0.0100 - 20s/epoch - 16ms/step\n",
      "Epoch 8/50\n",
      "1309/1309 - 20s - loss: 0.3740 - mse: 0.3538 - val_loss: 0.4429 - val_mse: 0.4429 - lr: 0.0100 - 20s/epoch - 16ms/step\n",
      "Epoch 9/50\n",
      "1309/1309 - 20s - loss: 0.3729 - mse: 0.3528 - val_loss: 0.4490 - val_mse: 0.4490 - lr: 0.0100 - 20s/epoch - 16ms/step\n",
      "Epoch 10/50\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "1309/1309 - 20s - loss: 0.3721 - mse: 0.3521 - val_loss: 0.4307 - val_mse: 0.4307 - lr: 0.0100 - 20s/epoch - 16ms/step\n",
      "Epoch 11/50\n",
      "1309/1309 - 20s - loss: 0.3666 - mse: 0.3470 - val_loss: 0.4362 - val_mse: 0.4362 - lr: 1.0000e-03 - 20s/epoch - 16ms/step\n",
      "Epoch 12/50\n",
      "1309/1309 - 20s - loss: 0.3654 - mse: 0.3459 - val_loss: 0.4301 - val_mse: 0.4301 - lr: 1.0000e-03 - 20s/epoch - 16ms/step\n",
      "Epoch 13/50\n",
      "1309/1309 - 20s - loss: 0.3646 - mse: 0.3452 - val_loss: 0.4273 - val_mse: 0.4273 - lr: 1.0000e-03 - 20s/epoch - 16ms/step\n",
      "Epoch 14/50\n",
      "1309/1309 - 20s - loss: 0.3645 - mse: 0.3451 - val_loss: 0.4233 - val_mse: 0.4233 - lr: 1.0000e-03 - 20s/epoch - 16ms/step\n",
      "Epoch 15/50\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "1309/1309 - 20s - loss: 0.3641 - mse: 0.3447 - val_loss: 0.4316 - val_mse: 0.4316 - lr: 1.0000e-03 - 20s/epoch - 16ms/step\n",
      "==================================================\n",
      "Step 8\n",
      "==================================================\n",
      "Epoch 1/50\n",
      "1309/1309 - 23s - loss: 0.3849 - mse: 0.3651 - val_loss: 0.3893 - val_mse: 0.3893 - lr: 0.0100 - 23s/epoch - 17ms/step\n",
      "Epoch 2/50\n",
      "1309/1309 - 20s - loss: 0.3678 - mse: 0.3495 - val_loss: 0.3846 - val_mse: 0.3846 - lr: 0.0100 - 20s/epoch - 16ms/step\n",
      "Epoch 3/50\n",
      "1309/1309 - 20s - loss: 0.3648 - mse: 0.3467 - val_loss: 0.4184 - val_mse: 0.4184 - lr: 0.0100 - 20s/epoch - 16ms/step\n",
      "Epoch 4/50\n",
      "1309/1309 - 20s - loss: 0.3636 - mse: 0.3456 - val_loss: 0.3895 - val_mse: 0.3895 - lr: 0.0100 - 20s/epoch - 16ms/step\n",
      "Epoch 5/50\n",
      "1309/1309 - 20s - loss: 0.3631 - mse: 0.3452 - val_loss: 0.3906 - val_mse: 0.3906 - lr: 0.0100 - 20s/epoch - 16ms/step\n",
      "Epoch 6/50\n",
      "1309/1309 - 20s - loss: 0.3620 - mse: 0.3442 - val_loss: 0.3787 - val_mse: 0.3787 - lr: 0.0100 - 20s/epoch - 16ms/step\n",
      "Epoch 7/50\n",
      "1309/1309 - 20s - loss: 0.3611 - mse: 0.3434 - val_loss: 0.3944 - val_mse: 0.3944 - lr: 0.0100 - 20s/epoch - 16ms/step\n",
      "Epoch 8/50\n",
      "1309/1309 - 20s - loss: 0.3603 - mse: 0.3426 - val_loss: 0.3894 - val_mse: 0.3894 - lr: 0.0100 - 20s/epoch - 16ms/step\n",
      "Epoch 9/50\n",
      "1309/1309 - 20s - loss: 0.3595 - mse: 0.3420 - val_loss: 0.3866 - val_mse: 0.3866 - lr: 0.0100 - 20s/epoch - 16ms/step\n",
      "Epoch 10/50\n",
      "1309/1309 - 20s - loss: 0.3595 - mse: 0.3420 - val_loss: 0.3861 - val_mse: 0.3861 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 11/50\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "1309/1309 - 20s - loss: 0.3585 - mse: 0.3411 - val_loss: 0.4161 - val_mse: 0.4161 - lr: 0.0100 - 20s/epoch - 16ms/step\n",
      "Epoch 12/50\n",
      "1309/1309 - 20s - loss: 0.3525 - mse: 0.3355 - val_loss: 0.3878 - val_mse: 0.3878 - lr: 1.0000e-03 - 20s/epoch - 16ms/step\n",
      "Epoch 13/50\n",
      "1309/1309 - 20s - loss: 0.3513 - mse: 0.3345 - val_loss: 0.3900 - val_mse: 0.3900 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 14/50\n",
      "1309/1309 - 20s - loss: 0.3511 - mse: 0.3343 - val_loss: 0.3890 - val_mse: 0.3890 - lr: 1.0000e-03 - 20s/epoch - 16ms/step\n",
      "Epoch 15/50\n",
      "1309/1309 - 20s - loss: 0.3500 - mse: 0.3332 - val_loss: 0.3863 - val_mse: 0.3863 - lr: 1.0000e-03 - 20s/epoch - 16ms/step\n",
      "Epoch 16/50\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "1309/1309 - 20s - loss: 0.3497 - mse: 0.3329 - val_loss: 0.3917 - val_mse: 0.3917 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "==================================================\n",
      "Step 9\n",
      "==================================================\n",
      "Epoch 1/50\n",
      "1309/1309 - 22s - loss: 0.3936 - mse: 0.3716 - val_loss: 0.3852 - val_mse: 0.3852 - lr: 0.0100 - 22s/epoch - 17ms/step\n",
      "Epoch 2/50\n",
      "1309/1309 - 20s - loss: 0.3776 - mse: 0.3568 - val_loss: 0.4126 - val_mse: 0.4126 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 3/50\n",
      "1309/1309 - 20s - loss: 0.3767 - mse: 0.3559 - val_loss: 0.3919 - val_mse: 0.3919 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 4/50\n",
      "1309/1309 - 20s - loss: 0.3759 - mse: 0.3552 - val_loss: 0.3783 - val_mse: 0.3783 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 5/50\n",
      "1309/1309 - 20s - loss: 0.3748 - mse: 0.3542 - val_loss: 0.3806 - val_mse: 0.3806 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 6/50\n",
      "1309/1309 - 20s - loss: 0.3735 - mse: 0.3530 - val_loss: 0.3844 - val_mse: 0.3844 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 7/50\n",
      "1309/1309 - 20s - loss: 0.3724 - mse: 0.3520 - val_loss: 0.3780 - val_mse: 0.3780 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 8/50\n",
      "1309/1309 - 20s - loss: 0.3724 - mse: 0.3520 - val_loss: 0.3872 - val_mse: 0.3872 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 9/50\n",
      "1309/1309 - 20s - loss: 0.3722 - mse: 0.3518 - val_loss: 0.3845 - val_mse: 0.3845 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 10/50\n",
      "1309/1309 - 20s - loss: 0.3713 - mse: 0.3510 - val_loss: 0.3816 - val_mse: 0.3816 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 11/50\n",
      "1309/1309 - 20s - loss: 0.3703 - mse: 0.3502 - val_loss: 0.3746 - val_mse: 0.3746 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 12/50\n",
      "1309/1309 - 20s - loss: 0.3700 - mse: 0.3498 - val_loss: 0.3775 - val_mse: 0.3775 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 13/50\n",
      "1309/1309 - 20s - loss: 0.3700 - mse: 0.3499 - val_loss: 0.3855 - val_mse: 0.3855 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 14/50\n",
      "1309/1309 - 20s - loss: 0.3695 - mse: 0.3494 - val_loss: 0.3890 - val_mse: 0.3890 - lr: 0.0100 - 20s/epoch - 16ms/step\n",
      "Epoch 15/50\n",
      "1309/1309 - 20s - loss: 0.3690 - mse: 0.3489 - val_loss: 0.3796 - val_mse: 0.3796 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 16/50\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "1309/1309 - 20s - loss: 0.3689 - mse: 0.3488 - val_loss: 0.3808 - val_mse: 0.3808 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 17/50\n",
      "1309/1309 - 20s - loss: 0.3640 - mse: 0.3443 - val_loss: 0.3752 - val_mse: 0.3752 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 18/50\n",
      "1309/1309 - 20s - loss: 0.3629 - mse: 0.3433 - val_loss: 0.3788 - val_mse: 0.3788 - lr: 1.0000e-03 - 20s/epoch - 16ms/step\n",
      "Epoch 19/50\n",
      "1309/1309 - 20s - loss: 0.3622 - mse: 0.3426 - val_loss: 0.3784 - val_mse: 0.3784 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50\n",
      "1309/1309 - 20s - loss: 0.3616 - mse: 0.3421 - val_loss: 0.3769 - val_mse: 0.3769 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 21/50\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "1309/1309 - 20s - loss: 0.3615 - mse: 0.3420 - val_loss: 0.3843 - val_mse: 0.3843 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "==================================================\n",
      "Step 10\n",
      "==================================================\n",
      "Epoch 1/50\n",
      "1309/1309 - 23s - loss: 0.4012 - mse: 0.3799 - val_loss: 0.3772 - val_mse: 0.3772 - lr: 0.0100 - 23s/epoch - 17ms/step\n",
      "Epoch 2/50\n",
      "1309/1309 - 21s - loss: 0.3839 - mse: 0.3640 - val_loss: 0.3680 - val_mse: 0.3680 - lr: 0.0100 - 21s/epoch - 16ms/step\n",
      "Epoch 3/50\n",
      "1309/1309 - 21s - loss: 0.3822 - mse: 0.3625 - val_loss: 0.3742 - val_mse: 0.3742 - lr: 0.0100 - 21s/epoch - 16ms/step\n",
      "Epoch 4/50\n",
      "1309/1309 - 21s - loss: 0.3807 - mse: 0.3612 - val_loss: 0.3690 - val_mse: 0.3690 - lr: 0.0100 - 21s/epoch - 16ms/step\n",
      "Epoch 5/50\n",
      "1309/1309 - 20s - loss: 0.3796 - mse: 0.3602 - val_loss: 0.3772 - val_mse: 0.3772 - lr: 0.0100 - 20s/epoch - 16ms/step\n",
      "Epoch 6/50\n",
      "1309/1309 - 20s - loss: 0.3784 - mse: 0.3591 - val_loss: 0.3751 - val_mse: 0.3751 - lr: 0.0100 - 20s/epoch - 16ms/step\n",
      "Epoch 7/50\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "1309/1309 - 20s - loss: 0.3779 - mse: 0.3586 - val_loss: 0.3698 - val_mse: 0.3698 - lr: 0.0100 - 20s/epoch - 16ms/step\n",
      "Epoch 8/50\n",
      "1309/1309 - 20s - loss: 0.3708 - mse: 0.3521 - val_loss: 0.3669 - val_mse: 0.3669 - lr: 1.0000e-03 - 20s/epoch - 16ms/step\n",
      "Epoch 9/50\n",
      "1309/1309 - 20s - loss: 0.3693 - mse: 0.3507 - val_loss: 0.3673 - val_mse: 0.3673 - lr: 1.0000e-03 - 20s/epoch - 16ms/step\n",
      "Epoch 10/50\n",
      "1309/1309 - 21s - loss: 0.3684 - mse: 0.3499 - val_loss: 0.3669 - val_mse: 0.3669 - lr: 1.0000e-03 - 21s/epoch - 16ms/step\n",
      "Epoch 11/50\n",
      "1309/1309 - 21s - loss: 0.3676 - mse: 0.3491 - val_loss: 0.3663 - val_mse: 0.3663 - lr: 1.0000e-03 - 21s/epoch - 16ms/step\n",
      "Epoch 12/50\n",
      "1309/1309 - 21s - loss: 0.3674 - mse: 0.3489 - val_loss: 0.3697 - val_mse: 0.3697 - lr: 1.0000e-03 - 21s/epoch - 16ms/step\n",
      "Epoch 13/50\n",
      "1309/1309 - 21s - loss: 0.3668 - mse: 0.3484 - val_loss: 0.3667 - val_mse: 0.3667 - lr: 1.0000e-03 - 21s/epoch - 16ms/step\n",
      "Epoch 14/50\n",
      "1309/1309 - 20s - loss: 0.3666 - mse: 0.3482 - val_loss: 0.3663 - val_mse: 0.3663 - lr: 1.0000e-03 - 20s/epoch - 16ms/step\n",
      "Epoch 15/50\n",
      "1309/1309 - 20s - loss: 0.3662 - mse: 0.3479 - val_loss: 0.3646 - val_mse: 0.3646 - lr: 1.0000e-03 - 20s/epoch - 16ms/step\n",
      "Epoch 16/50\n",
      "1309/1309 - 20s - loss: 0.3659 - mse: 0.3475 - val_loss: 0.3665 - val_mse: 0.3665 - lr: 1.0000e-03 - 20s/epoch - 16ms/step\n",
      "Epoch 17/50\n",
      "1309/1309 - 20s - loss: 0.3658 - mse: 0.3474 - val_loss: 0.3643 - val_mse: 0.3643 - lr: 1.0000e-03 - 20s/epoch - 16ms/step\n",
      "Epoch 18/50\n",
      "1309/1309 - 20s - loss: 0.3651 - mse: 0.3468 - val_loss: 0.3638 - val_mse: 0.3638 - lr: 1.0000e-03 - 20s/epoch - 16ms/step\n",
      "Epoch 19/50\n",
      "1309/1309 - 21s - loss: 0.3650 - mse: 0.3468 - val_loss: 0.3650 - val_mse: 0.3650 - lr: 1.0000e-03 - 21s/epoch - 16ms/step\n",
      "Epoch 20/50\n",
      "1309/1309 - 20s - loss: 0.3650 - mse: 0.3467 - val_loss: 0.3642 - val_mse: 0.3642 - lr: 1.0000e-03 - 20s/epoch - 16ms/step\n",
      "Epoch 21/50\n",
      "1309/1309 - 20s - loss: 0.3646 - mse: 0.3464 - val_loss: 0.3668 - val_mse: 0.3668 - lr: 1.0000e-03 - 20s/epoch - 16ms/step\n",
      "Epoch 22/50\n",
      "1309/1309 - 20s - loss: 0.3644 - mse: 0.3462 - val_loss: 0.3631 - val_mse: 0.3631 - lr: 1.0000e-03 - 20s/epoch - 16ms/step\n",
      "Epoch 23/50\n",
      "1309/1309 - 20s - loss: 0.3643 - mse: 0.3461 - val_loss: 0.3643 - val_mse: 0.3643 - lr: 1.0000e-03 - 20s/epoch - 16ms/step\n",
      "Epoch 24/50\n",
      "1309/1309 - 21s - loss: 0.3641 - mse: 0.3459 - val_loss: 0.3673 - val_mse: 0.3673 - lr: 1.0000e-03 - 21s/epoch - 16ms/step\n",
      "Epoch 25/50\n",
      "1309/1309 - 20s - loss: 0.3640 - mse: 0.3458 - val_loss: 0.3680 - val_mse: 0.3680 - lr: 1.0000e-03 - 20s/epoch - 16ms/step\n",
      "Epoch 26/50\n",
      "1309/1309 - 20s - loss: 0.3637 - mse: 0.3455 - val_loss: 0.3676 - val_mse: 0.3676 - lr: 1.0000e-03 - 20s/epoch - 16ms/step\n",
      "Epoch 27/50\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "1309/1309 - 20s - loss: 0.3637 - mse: 0.3455 - val_loss: 0.3666 - val_mse: 0.3666 - lr: 1.0000e-03 - 20s/epoch - 16ms/step\n",
      "Epoch 28/50\n",
      "1309/1309 - 20s - loss: 0.3622 - mse: 0.3442 - val_loss: 0.3656 - val_mse: 0.3656 - lr: 1.0000e-04 - 20s/epoch - 16ms/step\n",
      "Epoch 29/50\n",
      "1309/1309 - 20s - loss: 0.3620 - mse: 0.3440 - val_loss: 0.3656 - val_mse: 0.3656 - lr: 1.0000e-04 - 20s/epoch - 16ms/step\n",
      "Epoch 30/50\n",
      "1309/1309 - 20s - loss: 0.3617 - mse: 0.3437 - val_loss: 0.3663 - val_mse: 0.3663 - lr: 1.0000e-04 - 20s/epoch - 16ms/step\n",
      "Epoch 31/50\n",
      "1309/1309 - 20s - loss: 0.3617 - mse: 0.3437 - val_loss: 0.3658 - val_mse: 0.3658 - lr: 1.0000e-04 - 20s/epoch - 16ms/step\n",
      "Epoch 32/50\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "1309/1309 - 20s - loss: 0.3616 - mse: 0.3436 - val_loss: 0.3659 - val_mse: 0.3659 - lr: 1.0000e-04 - 20s/epoch - 16ms/step\n",
      "==================================================\n",
      "Step 11\n",
      "==================================================\n",
      "Epoch 1/50\n",
      "1309/1309 - 23s - loss: 0.4377 - mse: 0.4142 - val_loss: 0.3819 - val_mse: 0.3819 - lr: 0.0100 - 23s/epoch - 17ms/step\n",
      "Epoch 2/50\n",
      "1309/1309 - 20s - loss: 0.4135 - mse: 0.3915 - val_loss: 0.3812 - val_mse: 0.3812 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 3/50\n",
      "1309/1309 - 20s - loss: 0.4106 - mse: 0.3888 - val_loss: 0.3880 - val_mse: 0.3880 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 4/50\n",
      "1309/1309 - 20s - loss: 0.4094 - mse: 0.3878 - val_loss: 0.3874 - val_mse: 0.3874 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 5/50\n",
      "1309/1309 - 20s - loss: 0.4084 - mse: 0.3869 - val_loss: 0.3768 - val_mse: 0.3768 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 6/50\n",
      "1309/1309 - 20s - loss: 0.4070 - mse: 0.3856 - val_loss: 0.3909 - val_mse: 0.3909 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 7/50\n",
      "1309/1309 - 20s - loss: 0.4064 - mse: 0.3850 - val_loss: 0.3762 - val_mse: 0.3762 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 8/50\n",
      "1309/1309 - 20s - loss: 0.4056 - mse: 0.3843 - val_loss: 0.3778 - val_mse: 0.3778 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 9/50\n",
      "1309/1309 - 20s - loss: 0.4051 - mse: 0.3839 - val_loss: 0.3805 - val_mse: 0.3805 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 10/50\n",
      "1309/1309 - 20s - loss: 0.4035 - mse: 0.3824 - val_loss: 0.3801 - val_mse: 0.3801 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 11/50\n",
      "1309/1309 - 20s - loss: 0.4036 - mse: 0.3825 - val_loss: 0.3804 - val_mse: 0.3804 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 12/50\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "1309/1309 - 20s - loss: 0.4032 - mse: 0.3821 - val_loss: 0.3768 - val_mse: 0.3768 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 13/50\n",
      "1309/1309 - 20s - loss: 0.3967 - mse: 0.3761 - val_loss: 0.3718 - val_mse: 0.3718 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 14/50\n",
      "1309/1309 - 20s - loss: 0.3951 - mse: 0.3745 - val_loss: 0.3714 - val_mse: 0.3714 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 15/50\n",
      "1309/1309 - 20s - loss: 0.3942 - mse: 0.3738 - val_loss: 0.3712 - val_mse: 0.3712 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 16/50\n",
      "1309/1309 - 20s - loss: 0.3942 - mse: 0.3737 - val_loss: 0.3712 - val_mse: 0.3712 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 17/50\n",
      "1309/1309 - 20s - loss: 0.3934 - mse: 0.3730 - val_loss: 0.3725 - val_mse: 0.3725 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 18/50\n",
      "1309/1309 - 20s - loss: 0.3931 - mse: 0.3728 - val_loss: 0.3717 - val_mse: 0.3717 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 19/50\n",
      "1309/1309 - 20s - loss: 0.3928 - mse: 0.3725 - val_loss: 0.3718 - val_mse: 0.3718 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 20/50\n",
      "1309/1309 - 20s - loss: 0.3925 - mse: 0.3722 - val_loss: 0.3717 - val_mse: 0.3717 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 21/50\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "1309/1309 - 20s - loss: 0.3923 - mse: 0.3720 - val_loss: 0.3714 - val_mse: 0.3714 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 22/50\n",
      "1309/1309 - 20s - loss: 0.3912 - mse: 0.3710 - val_loss: 0.3711 - val_mse: 0.3711 - lr: 1.0000e-04 - 20s/epoch - 15ms/step\n",
      "Epoch 23/50\n",
      "1309/1309 - 20s - loss: 0.3911 - mse: 0.3709 - val_loss: 0.3713 - val_mse: 0.3713 - lr: 1.0000e-04 - 20s/epoch - 15ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50\n",
      "1309/1309 - 20s - loss: 0.3907 - mse: 0.3706 - val_loss: 0.3713 - val_mse: 0.3713 - lr: 1.0000e-04 - 20s/epoch - 15ms/step\n",
      "Epoch 25/50\n",
      "1309/1309 - 20s - loss: 0.3906 - mse: 0.3705 - val_loss: 0.3715 - val_mse: 0.3715 - lr: 1.0000e-04 - 20s/epoch - 15ms/step\n",
      "Epoch 26/50\n",
      "1309/1309 - 20s - loss: 0.3908 - mse: 0.3706 - val_loss: 0.3714 - val_mse: 0.3714 - lr: 1.0000e-04 - 20s/epoch - 16ms/step\n",
      "Epoch 27/50\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "1309/1309 - 20s - loss: 0.3907 - mse: 0.3705 - val_loss: 0.3713 - val_mse: 0.3713 - lr: 1.0000e-04 - 20s/epoch - 15ms/step\n",
      "Epoch 28/50\n",
      "1309/1309 - 20s - loss: 0.3905 - mse: 0.3703 - val_loss: 0.3713 - val_mse: 0.3713 - lr: 1.0000e-05 - 20s/epoch - 15ms/step\n",
      "Epoch 29/50\n",
      "1309/1309 - 20s - loss: 0.3906 - mse: 0.3705 - val_loss: 0.3713 - val_mse: 0.3713 - lr: 1.0000e-05 - 20s/epoch - 16ms/step\n",
      "Epoch 30/50\n",
      "1309/1309 - 20s - loss: 0.3904 - mse: 0.3702 - val_loss: 0.3714 - val_mse: 0.3714 - lr: 1.0000e-05 - 20s/epoch - 15ms/step\n",
      "Epoch 31/50\n",
      "1309/1309 - 20s - loss: 0.3905 - mse: 0.3703 - val_loss: 0.3714 - val_mse: 0.3714 - lr: 1.0000e-05 - 20s/epoch - 15ms/step\n",
      "Epoch 32/50\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
      "1309/1309 - 20s - loss: 0.3905 - mse: 0.3703 - val_loss: 0.3714 - val_mse: 0.3714 - lr: 1.0000e-05 - 20s/epoch - 16ms/step\n",
      "==================================================\n",
      "Step 12\n",
      "==================================================\n",
      "Epoch 1/50\n",
      "1309/1309 - 22s - loss: 0.4419 - mse: 0.4182 - val_loss: 0.4052 - val_mse: 0.4052 - lr: 0.0100 - 22s/epoch - 17ms/step\n",
      "Epoch 2/50\n",
      "1309/1309 - 20s - loss: 0.4235 - mse: 0.4012 - val_loss: 0.3926 - val_mse: 0.3926 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 3/50\n",
      "1309/1309 - 20s - loss: 0.4208 - mse: 0.3988 - val_loss: 0.3937 - val_mse: 0.3937 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 4/50\n",
      "1309/1309 - 20s - loss: 0.4190 - mse: 0.3971 - val_loss: 0.3863 - val_mse: 0.3863 - lr: 0.0100 - 20s/epoch - 16ms/step\n",
      "Epoch 5/50\n",
      "1309/1309 - 20s - loss: 0.4184 - mse: 0.3965 - val_loss: 0.3949 - val_mse: 0.3949 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 6/50\n",
      "1309/1309 - 20s - loss: 0.4165 - mse: 0.3948 - val_loss: 0.3928 - val_mse: 0.3928 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 7/50\n",
      "1309/1309 - 20s - loss: 0.4159 - mse: 0.3943 - val_loss: 0.3870 - val_mse: 0.3870 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 8/50\n",
      "1309/1309 - 20s - loss: 0.4146 - mse: 0.3931 - val_loss: 0.3868 - val_mse: 0.3868 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 9/50\n",
      "1309/1309 - 20s - loss: 0.4140 - mse: 0.3925 - val_loss: 0.3860 - val_mse: 0.3860 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 10/50\n",
      "1309/1309 - 20s - loss: 0.4126 - mse: 0.3913 - val_loss: 0.3870 - val_mse: 0.3870 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 11/50\n",
      "1309/1309 - 20s - loss: 0.4124 - mse: 0.3910 - val_loss: 0.3898 - val_mse: 0.3898 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 12/50\n",
      "1309/1309 - 20s - loss: 0.4120 - mse: 0.3907 - val_loss: 0.3895 - val_mse: 0.3895 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 13/50\n",
      "1309/1309 - 20s - loss: 0.4115 - mse: 0.3902 - val_loss: 0.3878 - val_mse: 0.3878 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 14/50\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "1309/1309 - 20s - loss: 0.4108 - mse: 0.3897 - val_loss: 0.3864 - val_mse: 0.3864 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 15/50\n",
      "1309/1309 - 20s - loss: 0.4044 - mse: 0.3837 - val_loss: 0.3825 - val_mse: 0.3825 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 16/50\n",
      "1309/1309 - 20s - loss: 0.4025 - mse: 0.3820 - val_loss: 0.3818 - val_mse: 0.3818 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 17/50\n",
      "1309/1309 - 20s - loss: 0.4019 - mse: 0.3814 - val_loss: 0.3839 - val_mse: 0.3839 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 18/50\n",
      "1309/1309 - 20s - loss: 0.4013 - mse: 0.3809 - val_loss: 0.3831 - val_mse: 0.3831 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 19/50\n",
      "1309/1309 - 20s - loss: 0.4009 - mse: 0.3805 - val_loss: 0.3836 - val_mse: 0.3836 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 20/50\n",
      "1309/1309 - 20s - loss: 0.4008 - mse: 0.3804 - val_loss: 0.3829 - val_mse: 0.3829 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 21/50\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "1309/1309 - 20s - loss: 0.4002 - mse: 0.3798 - val_loss: 0.3844 - val_mse: 0.3844 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 22/50\n",
      "1309/1309 - 20s - loss: 0.3994 - mse: 0.3791 - val_loss: 0.3825 - val_mse: 0.3825 - lr: 1.0000e-04 - 20s/epoch - 15ms/step\n",
      "Epoch 23/50\n",
      "1309/1309 - 20s - loss: 0.3987 - mse: 0.3785 - val_loss: 0.3826 - val_mse: 0.3826 - lr: 1.0000e-04 - 20s/epoch - 15ms/step\n",
      "Epoch 24/50\n",
      "1309/1309 - 20s - loss: 0.3989 - mse: 0.3787 - val_loss: 0.3828 - val_mse: 0.3828 - lr: 1.0000e-04 - 20s/epoch - 15ms/step\n",
      "Epoch 25/50\n",
      "1309/1309 - 20s - loss: 0.3987 - mse: 0.3785 - val_loss: 0.3827 - val_mse: 0.3827 - lr: 1.0000e-04 - 20s/epoch - 15ms/step\n",
      "Epoch 26/50\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "1309/1309 - 20s - loss: 0.3986 - mse: 0.3783 - val_loss: 0.3827 - val_mse: 0.3827 - lr: 1.0000e-04 - 20s/epoch - 15ms/step\n",
      "==================================================\n",
      "Step 13\n",
      "==================================================\n",
      "Epoch 1/50\n",
      "1309/1309 - 22s - loss: 0.4241 - mse: 0.4000 - val_loss: 0.3826 - val_mse: 0.3826 - lr: 0.0100 - 22s/epoch - 17ms/step\n",
      "Epoch 2/50\n",
      "1309/1309 - 20s - loss: 0.4107 - mse: 0.3877 - val_loss: 0.3852 - val_mse: 0.3852 - lr: 0.0100 - 20s/epoch - 16ms/step\n",
      "Epoch 3/50\n",
      "1309/1309 - 20s - loss: 0.4092 - mse: 0.3862 - val_loss: 0.3876 - val_mse: 0.3876 - lr: 0.0100 - 20s/epoch - 16ms/step\n",
      "Epoch 4/50\n",
      "1309/1309 - 20s - loss: 0.4084 - mse: 0.3856 - val_loss: 0.3848 - val_mse: 0.3848 - lr: 0.0100 - 20s/epoch - 16ms/step\n",
      "Epoch 5/50\n",
      "1309/1309 - 20s - loss: 0.4078 - mse: 0.3850 - val_loss: 0.3770 - val_mse: 0.3770 - lr: 0.0100 - 20s/epoch - 16ms/step\n",
      "Epoch 6/50\n",
      "1309/1309 - 20s - loss: 0.4059 - mse: 0.3833 - val_loss: 0.3792 - val_mse: 0.3792 - lr: 0.0100 - 20s/epoch - 16ms/step\n",
      "Epoch 7/50\n",
      "1309/1309 - 20s - loss: 0.4050 - mse: 0.3825 - val_loss: 0.3899 - val_mse: 0.3899 - lr: 0.0100 - 20s/epoch - 16ms/step\n",
      "Epoch 8/50\n",
      "1309/1309 - 20s - loss: 0.4047 - mse: 0.3822 - val_loss: 0.3800 - val_mse: 0.3800 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 9/50\n",
      "1309/1309 - 20s - loss: 0.4040 - mse: 0.3815 - val_loss: 0.3812 - val_mse: 0.3812 - lr: 0.0100 - 20s/epoch - 16ms/step\n",
      "Epoch 10/50\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "1309/1309 - 20s - loss: 0.4032 - mse: 0.3808 - val_loss: 0.3772 - val_mse: 0.3772 - lr: 0.0100 - 20s/epoch - 16ms/step\n",
      "Epoch 11/50\n",
      "1309/1309 - 20s - loss: 0.3971 - mse: 0.3752 - val_loss: 0.3744 - val_mse: 0.3744 - lr: 1.0000e-03 - 20s/epoch - 16ms/step\n",
      "Epoch 12/50\n",
      "1309/1309 - 20s - loss: 0.3956 - mse: 0.3738 - val_loss: 0.3743 - val_mse: 0.3743 - lr: 1.0000e-03 - 20s/epoch - 16ms/step\n",
      "Epoch 13/50\n",
      "1309/1309 - 20s - loss: 0.3949 - mse: 0.3731 - val_loss: 0.3748 - val_mse: 0.3748 - lr: 1.0000e-03 - 20s/epoch - 16ms/step\n",
      "Epoch 14/50\n",
      "1309/1309 - 20s - loss: 0.3945 - mse: 0.3728 - val_loss: 0.3750 - val_mse: 0.3750 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 15/50\n",
      "1309/1309 - 20s - loss: 0.3938 - mse: 0.3722 - val_loss: 0.3749 - val_mse: 0.3749 - lr: 1.0000e-03 - 20s/epoch - 16ms/step\n",
      "Epoch 16/50\n",
      "1309/1309 - 20s - loss: 0.3935 - mse: 0.3719 - val_loss: 0.3740 - val_mse: 0.3740 - lr: 1.0000e-03 - 20s/epoch - 16ms/step\n",
      "Epoch 17/50\n",
      "1309/1309 - 20s - loss: 0.3936 - mse: 0.3720 - val_loss: 0.3742 - val_mse: 0.3742 - lr: 1.0000e-03 - 20s/epoch - 16ms/step\n",
      "Epoch 18/50\n",
      "1309/1309 - 20s - loss: 0.3930 - mse: 0.3714 - val_loss: 0.3744 - val_mse: 0.3744 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 19/50\n",
      "1309/1309 - 20s - loss: 0.3924 - mse: 0.3709 - val_loss: 0.3746 - val_mse: 0.3746 - lr: 1.0000e-03 - 20s/epoch - 16ms/step\n",
      "Epoch 20/50\n",
      "1309/1309 - 20s - loss: 0.3923 - mse: 0.3707 - val_loss: 0.3744 - val_mse: 0.3744 - lr: 1.0000e-03 - 20s/epoch - 16ms/step\n",
      "Epoch 21/50\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "1309/1309 - 20s - loss: 0.3921 - mse: 0.3706 - val_loss: 0.3755 - val_mse: 0.3755 - lr: 1.0000e-03 - 20s/epoch - 16ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50\n",
      "1309/1309 - 20s - loss: 0.3911 - mse: 0.3697 - val_loss: 0.3745 - val_mse: 0.3745 - lr: 1.0000e-04 - 20s/epoch - 16ms/step\n",
      "Epoch 23/50\n",
      "1309/1309 - 20s - loss: 0.3909 - mse: 0.3695 - val_loss: 0.3744 - val_mse: 0.3744 - lr: 1.0000e-04 - 20s/epoch - 16ms/step\n",
      "Epoch 24/50\n",
      "1309/1309 - 20s - loss: 0.3907 - mse: 0.3693 - val_loss: 0.3743 - val_mse: 0.3743 - lr: 1.0000e-04 - 20s/epoch - 16ms/step\n",
      "Epoch 25/50\n",
      "1309/1309 - 20s - loss: 0.3904 - mse: 0.3691 - val_loss: 0.3743 - val_mse: 0.3743 - lr: 1.0000e-04 - 20s/epoch - 16ms/step\n",
      "Epoch 26/50\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "1309/1309 - 20s - loss: 0.3906 - mse: 0.3692 - val_loss: 0.3742 - val_mse: 0.3742 - lr: 1.0000e-04 - 20s/epoch - 16ms/step\n",
      "==================================================\n",
      "Step 14\n",
      "==================================================\n",
      "Epoch 1/50\n",
      "1309/1309 - 23s - loss: 0.4276 - mse: 0.4039 - val_loss: 0.3702 - val_mse: 0.3702 - lr: 0.0100 - 23s/epoch - 17ms/step\n",
      "Epoch 2/50\n",
      "1309/1309 - 20s - loss: 0.4069 - mse: 0.3849 - val_loss: 0.3663 - val_mse: 0.3663 - lr: 0.0100 - 20s/epoch - 16ms/step\n",
      "Epoch 3/50\n",
      "1309/1309 - 20s - loss: 0.4051 - mse: 0.3833 - val_loss: 0.3666 - val_mse: 0.3666 - lr: 0.0100 - 20s/epoch - 16ms/step\n",
      "Epoch 4/50\n",
      "1309/1309 - 20s - loss: 0.4037 - mse: 0.3821 - val_loss: 0.3657 - val_mse: 0.3657 - lr: 0.0100 - 20s/epoch - 16ms/step\n",
      "Epoch 5/50\n",
      "1309/1309 - 20s - loss: 0.4032 - mse: 0.3816 - val_loss: 0.3694 - val_mse: 0.3694 - lr: 0.0100 - 20s/epoch - 16ms/step\n",
      "Epoch 6/50\n",
      "1309/1309 - 20s - loss: 0.4019 - mse: 0.3804 - val_loss: 0.3704 - val_mse: 0.3704 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 7/50\n",
      "1309/1309 - 20s - loss: 0.4013 - mse: 0.3798 - val_loss: 0.3829 - val_mse: 0.3829 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 8/50\n",
      "1309/1309 - 20s - loss: 0.4008 - mse: 0.3794 - val_loss: 0.3763 - val_mse: 0.3763 - lr: 0.0100 - 20s/epoch - 16ms/step\n",
      "Epoch 9/50\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "1309/1309 - 20s - loss: 0.3997 - mse: 0.3784 - val_loss: 0.3692 - val_mse: 0.3692 - lr: 0.0100 - 20s/epoch - 16ms/step\n",
      "Epoch 10/50\n",
      "1309/1309 - 20s - loss: 0.3939 - mse: 0.3731 - val_loss: 0.3601 - val_mse: 0.3601 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 11/50\n",
      "1309/1309 - 20s - loss: 0.3921 - mse: 0.3714 - val_loss: 0.3610 - val_mse: 0.3610 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 12/50\n",
      "1309/1309 - 20s - loss: 0.3915 - mse: 0.3709 - val_loss: 0.3606 - val_mse: 0.3606 - lr: 1.0000e-03 - 20s/epoch - 16ms/step\n",
      "Epoch 13/50\n",
      "1309/1309 - 20s - loss: 0.3908 - mse: 0.3703 - val_loss: 0.3599 - val_mse: 0.3599 - lr: 1.0000e-03 - 20s/epoch - 16ms/step\n",
      "Epoch 14/50\n",
      "1309/1309 - 20s - loss: 0.3903 - mse: 0.3698 - val_loss: 0.3606 - val_mse: 0.3606 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 15/50\n",
      "1309/1309 - 20s - loss: 0.3899 - mse: 0.3694 - val_loss: 0.3613 - val_mse: 0.3613 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 16/50\n",
      "1309/1309 - 20s - loss: 0.3896 - mse: 0.3691 - val_loss: 0.3606 - val_mse: 0.3606 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 17/50\n",
      "1309/1309 - 20s - loss: 0.3893 - mse: 0.3688 - val_loss: 0.3608 - val_mse: 0.3608 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 18/50\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "1309/1309 - 20s - loss: 0.3891 - mse: 0.3686 - val_loss: 0.3606 - val_mse: 0.3606 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 19/50\n",
      "1309/1309 - 20s - loss: 0.3881 - mse: 0.3677 - val_loss: 0.3603 - val_mse: 0.3603 - lr: 1.0000e-04 - 20s/epoch - 16ms/step\n",
      "Epoch 20/50\n",
      "1309/1309 - 20s - loss: 0.3876 - mse: 0.3673 - val_loss: 0.3601 - val_mse: 0.3601 - lr: 1.0000e-04 - 20s/epoch - 15ms/step\n",
      "Epoch 21/50\n",
      "1309/1309 - 20s - loss: 0.3877 - mse: 0.3674 - val_loss: 0.3602 - val_mse: 0.3602 - lr: 1.0000e-04 - 20s/epoch - 15ms/step\n",
      "Epoch 22/50\n",
      "1309/1309 - 20s - loss: 0.3877 - mse: 0.3674 - val_loss: 0.3601 - val_mse: 0.3601 - lr: 1.0000e-04 - 20s/epoch - 15ms/step\n",
      "Epoch 23/50\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "1309/1309 - 20s - loss: 0.3878 - mse: 0.3675 - val_loss: 0.3601 - val_mse: 0.3601 - lr: 1.0000e-04 - 20s/epoch - 15ms/step\n",
      "==================================================\n",
      "Step 15\n",
      "==================================================\n",
      "Epoch 1/50\n",
      "1309/1309 - 23s - loss: 0.4178 - mse: 0.3964 - val_loss: 0.3549 - val_mse: 0.3549 - lr: 0.0100 - 23s/epoch - 17ms/step\n",
      "Epoch 2/50\n",
      "1309/1309 - 21s - loss: 0.3908 - mse: 0.3715 - val_loss: 0.3536 - val_mse: 0.3536 - lr: 0.0100 - 21s/epoch - 16ms/step\n",
      "Epoch 3/50\n",
      "1309/1309 - 21s - loss: 0.3885 - mse: 0.3694 - val_loss: 0.3507 - val_mse: 0.3507 - lr: 0.0100 - 21s/epoch - 16ms/step\n",
      "Epoch 4/50\n",
      "1309/1309 - 21s - loss: 0.3868 - mse: 0.3679 - val_loss: 0.3655 - val_mse: 0.3655 - lr: 0.0100 - 21s/epoch - 16ms/step\n",
      "Epoch 5/50\n",
      "1309/1309 - 21s - loss: 0.3865 - mse: 0.3677 - val_loss: 0.3564 - val_mse: 0.3564 - lr: 0.0100 - 21s/epoch - 16ms/step\n",
      "Epoch 6/50\n",
      "1309/1309 - 21s - loss: 0.3853 - mse: 0.3666 - val_loss: 0.3504 - val_mse: 0.3504 - lr: 0.0100 - 21s/epoch - 16ms/step\n",
      "Epoch 7/50\n",
      "1309/1309 - 21s - loss: 0.3840 - mse: 0.3654 - val_loss: 0.3515 - val_mse: 0.3515 - lr: 0.0100 - 21s/epoch - 16ms/step\n",
      "Epoch 8/50\n",
      "1309/1309 - 21s - loss: 0.3833 - mse: 0.3647 - val_loss: 0.3523 - val_mse: 0.3523 - lr: 0.0100 - 21s/epoch - 16ms/step\n",
      "Epoch 9/50\n",
      "1309/1309 - 21s - loss: 0.3826 - mse: 0.3641 - val_loss: 0.3508 - val_mse: 0.3508 - lr: 0.0100 - 21s/epoch - 16ms/step\n",
      "Epoch 10/50\n",
      "1309/1309 - 21s - loss: 0.3818 - mse: 0.3634 - val_loss: 0.3503 - val_mse: 0.3503 - lr: 0.0100 - 21s/epoch - 16ms/step\n",
      "Epoch 11/50\n",
      "1309/1309 - 21s - loss: 0.3814 - mse: 0.3630 - val_loss: 0.3529 - val_mse: 0.3529 - lr: 0.0100 - 21s/epoch - 16ms/step\n",
      "Epoch 12/50\n",
      "1309/1309 - 21s - loss: 0.3803 - mse: 0.3620 - val_loss: 0.3610 - val_mse: 0.3610 - lr: 0.0100 - 21s/epoch - 16ms/step\n",
      "Epoch 13/50\n",
      "1309/1309 - 21s - loss: 0.3801 - mse: 0.3618 - val_loss: 0.3597 - val_mse: 0.3597 - lr: 0.0100 - 21s/epoch - 16ms/step\n",
      "Epoch 14/50\n",
      "1309/1309 - 21s - loss: 0.3801 - mse: 0.3618 - val_loss: 0.3504 - val_mse: 0.3504 - lr: 0.0100 - 21s/epoch - 16ms/step\n",
      "Epoch 15/50\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "1309/1309 - 21s - loss: 0.3794 - mse: 0.3612 - val_loss: 0.3512 - val_mse: 0.3512 - lr: 0.0100 - 21s/epoch - 16ms/step\n",
      "Epoch 16/50\n",
      "1309/1309 - 21s - loss: 0.3737 - mse: 0.3560 - val_loss: 0.3470 - val_mse: 0.3470 - lr: 1.0000e-03 - 21s/epoch - 16ms/step\n",
      "Epoch 17/50\n",
      "1309/1309 - 21s - loss: 0.3724 - mse: 0.3547 - val_loss: 0.3470 - val_mse: 0.3470 - lr: 1.0000e-03 - 21s/epoch - 16ms/step\n",
      "Epoch 18/50\n",
      "1309/1309 - 21s - loss: 0.3716 - mse: 0.3539 - val_loss: 0.3460 - val_mse: 0.3460 - lr: 1.0000e-03 - 21s/epoch - 16ms/step\n",
      "Epoch 19/50\n",
      "1309/1309 - 21s - loss: 0.3711 - mse: 0.3535 - val_loss: 0.3461 - val_mse: 0.3461 - lr: 1.0000e-03 - 21s/epoch - 16ms/step\n",
      "Epoch 20/50\n",
      "1309/1309 - 21s - loss: 0.3707 - mse: 0.3532 - val_loss: 0.3457 - val_mse: 0.3457 - lr: 1.0000e-03 - 21s/epoch - 16ms/step\n",
      "Epoch 21/50\n",
      "1309/1309 - 20s - loss: 0.3703 - mse: 0.3528 - val_loss: 0.3463 - val_mse: 0.3463 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 22/50\n",
      "1309/1309 - 20s - loss: 0.3703 - mse: 0.3527 - val_loss: 0.3460 - val_mse: 0.3460 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 23/50\n",
      "1309/1309 - 20s - loss: 0.3700 - mse: 0.3525 - val_loss: 0.3465 - val_mse: 0.3465 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 24/50\n",
      "1309/1309 - 20s - loss: 0.3694 - mse: 0.3520 - val_loss: 0.3465 - val_mse: 0.3465 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 25/50\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "1309/1309 - 20s - loss: 0.3693 - mse: 0.3518 - val_loss: 0.3458 - val_mse: 0.3458 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 26/50\n",
      "1309/1309 - 20s - loss: 0.3685 - mse: 0.3511 - val_loss: 0.3457 - val_mse: 0.3457 - lr: 1.0000e-04 - 20s/epoch - 15ms/step\n",
      "Epoch 27/50\n",
      "1309/1309 - 20s - loss: 0.3683 - mse: 0.3510 - val_loss: 0.3458 - val_mse: 0.3458 - lr: 1.0000e-04 - 20s/epoch - 15ms/step\n",
      "Epoch 28/50\n",
      "1309/1309 - 20s - loss: 0.3683 - mse: 0.3509 - val_loss: 0.3457 - val_mse: 0.3457 - lr: 1.0000e-04 - 20s/epoch - 15ms/step\n",
      "Epoch 29/50\n",
      "1309/1309 - 20s - loss: 0.3680 - mse: 0.3507 - val_loss: 0.3459 - val_mse: 0.3459 - lr: 1.0000e-04 - 20s/epoch - 15ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "1309/1309 - 20s - loss: 0.3680 - mse: 0.3507 - val_loss: 0.3459 - val_mse: 0.3459 - lr: 1.0000e-04 - 20s/epoch - 15ms/step\n",
      "==================================================\n",
      "Step 16\n",
      "==================================================\n",
      "Epoch 1/50\n",
      "1309/1309 - 22s - loss: 0.4165 - mse: 0.3933 - val_loss: 0.3759 - val_mse: 0.3759 - lr: 0.0100 - 22s/epoch - 17ms/step\n",
      "Epoch 2/50\n",
      "1309/1309 - 20s - loss: 0.3986 - mse: 0.3768 - val_loss: 0.3770 - val_mse: 0.3770 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 3/50\n",
      "1309/1309 - 20s - loss: 0.3965 - mse: 0.3749 - val_loss: 0.3804 - val_mse: 0.3804 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 4/50\n",
      "1309/1309 - 20s - loss: 0.3960 - mse: 0.3744 - val_loss: 0.3735 - val_mse: 0.3735 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 5/50\n",
      "1309/1309 - 20s - loss: 0.3950 - mse: 0.3735 - val_loss: 0.3802 - val_mse: 0.3802 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 6/50\n",
      "1309/1309 - 20s - loss: 0.3940 - mse: 0.3726 - val_loss: 0.3741 - val_mse: 0.3741 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 7/50\n",
      "1309/1309 - 20s - loss: 0.3933 - mse: 0.3720 - val_loss: 0.3762 - val_mse: 0.3762 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 8/50\n",
      "1309/1309 - 20s - loss: 0.3929 - mse: 0.3716 - val_loss: 0.3757 - val_mse: 0.3757 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 9/50\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "1309/1309 - 20s - loss: 0.3921 - mse: 0.3709 - val_loss: 0.3739 - val_mse: 0.3739 - lr: 0.0100 - 20s/epoch - 15ms/step\n",
      "Epoch 10/50\n",
      "1309/1309 - 20s - loss: 0.3866 - mse: 0.3658 - val_loss: 0.3708 - val_mse: 0.3708 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 11/50\n",
      "1309/1309 - 20s - loss: 0.3848 - mse: 0.3642 - val_loss: 0.3699 - val_mse: 0.3699 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 12/50\n",
      "1309/1309 - 20s - loss: 0.3844 - mse: 0.3638 - val_loss: 0.3707 - val_mse: 0.3707 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 13/50\n",
      "1309/1309 - 20s - loss: 0.3835 - mse: 0.3630 - val_loss: 0.3708 - val_mse: 0.3708 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 14/50\n",
      "1309/1309 - 20s - loss: 0.3832 - mse: 0.3628 - val_loss: 0.3708 - val_mse: 0.3708 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 15/50\n",
      "1309/1309 - 20s - loss: 0.3828 - mse: 0.3623 - val_loss: 0.3701 - val_mse: 0.3701 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 16/50\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "1309/1309 - 20s - loss: 0.3826 - mse: 0.3621 - val_loss: 0.3711 - val_mse: 0.3711 - lr: 1.0000e-03 - 20s/epoch - 15ms/step\n",
      "Epoch 17/50\n",
      "1309/1309 - 20s - loss: 0.3816 - mse: 0.3612 - val_loss: 0.3699 - val_mse: 0.3699 - lr: 1.0000e-04 - 20s/epoch - 15ms/step\n",
      "Epoch 18/50\n",
      "1309/1309 - 20s - loss: 0.3814 - mse: 0.3611 - val_loss: 0.3700 - val_mse: 0.3700 - lr: 1.0000e-04 - 20s/epoch - 15ms/step\n",
      "Epoch 19/50\n",
      "1309/1309 - 20s - loss: 0.3812 - mse: 0.3608 - val_loss: 0.3699 - val_mse: 0.3699 - lr: 1.0000e-04 - 20s/epoch - 15ms/step\n",
      "Epoch 20/50\n",
      "1309/1309 - 20s - loss: 0.3812 - mse: 0.3609 - val_loss: 0.3700 - val_mse: 0.3700 - lr: 1.0000e-04 - 20s/epoch - 15ms/step\n",
      "Epoch 21/50\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "1309/1309 - 20s - loss: 0.3811 - mse: 0.3608 - val_loss: 0.3700 - val_mse: 0.3700 - lr: 1.0000e-04 - 20s/epoch - 15ms/step\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 50\n",
    "\n",
    "val_pred = []\n",
    "test_pred = []\n",
    "# wtpath = 'weights.hdf5'  # To save best epoch. But need Keras bug to be fixed first.\n",
    "sample_weights=np.array( pd.concat([items[\"perishable\"]] * num_days) * 0.25 + 1 )\n",
    "with tf.device('/device:GPU:0'):\n",
    "    for i in range(16):\n",
    "        model = build_model()\n",
    "        opt = optimizers.Adam(learning_rate=0.01)\n",
    "        model.compile(loss='mse', optimizer=opt, metrics=['mse'])\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=10, verbose=0),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_delta=1e-6, mode='min')\n",
    "            ]\n",
    "        print(\"=\" * 50)\n",
    "        print(\"Step %d\" % (i+1))\n",
    "        print(\"=\" * 50)\n",
    "        y = y_train[:, i]\n",
    "        xv = X_val\n",
    "        y_mean = y.mean()\n",
    "        yv = y_val[:, i]\n",
    "        model.fit(X_train, y  - y_mean, batch_size = 1024, epochs = N_EPOCHS, verbose=2,\n",
    "                   sample_weight=sample_weights, validation_data=(xv,yv - y_mean), callbacks=callbacks ) \n",
    "        val_pred.append(model.predict(X_val) + y_mean)\n",
    "        test_pred.append(model.predict(X_test) + y_mean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
